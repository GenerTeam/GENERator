# evaluation
do_eval: true
evaluation_strategy: "epoch"
load_best_model_at_end: true

# saving
save_strategy: "epoch"
save_total_limit: 3

# logging
logging_strategy: "steps"
logging_steps: 10

# training
num_train_epochs: 10000
weight_decay: 0.1
lr_scheduler_type: "reduce_lr_on_plateau"
lr_scheduler_kwargs: {
  "patience": 1,
  "factor": 0.5,
  "mode": null,
}
gradient_checkpointing: True
gradient_checkpointing_kwargs: { "use_reentrant": False }

# dataset
dataloader_num_workers: 4
remove_unused_columns: false

push_to_hub: false
report_to: [ "wandb" ]
